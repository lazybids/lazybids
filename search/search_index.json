{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"LazyBIDS Documentation","text":"<p>LazyBIDS is a Python package designed to simplify interactions with BIDS (Brain Imaging Data Structure) datasets. It provides an intuitive object-oriented interface for working with BIDS data, both locally and remotely through the lazybids-ui server.</p>"},{"location":"#overview","title":"Overview","text":"<p>LazyBIDS serves two main purposes:</p> <ol> <li>An I/O library for interacting with local BIDS datasets</li> <li>A client for remote interaction with datasets stored on a lazybids-ui server</li> </ol> <p>This dual functionality allows users to work with BIDS data consistently, regardless of whether it's stored locally or on a remote server.  </p>"},{"location":"#installation","title":"Installation","text":"<p>Install the latest version of LazyBIDS using pip: <pre><code>pip install lazybids\n</code></pre></p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Access all metadata of Dataset, Subject, Session, or Scan objects using the <code>all_metadata</code> property</li> <li>Retrieve contents of scan/measurement level .tsv files as pandas DataFrames via the <code>Scan.table</code> parameter</li> <li>Support for various imaging formats (via SimpleITK), including .nii, .nii.gz, and DICOM folders</li> <li>Limited support for MEG/EEG data</li> <li>Control memory usage by caching scan pixel/voxel data selectively</li> <li>Access scan pixel/voxel data as SimpleITK images or numpy arrays</li> <li>Seamless interaction with remote datasets on a lazybids-ui server, downloading only necessary data</li> </ul>"},{"location":"basic_usage/","title":"Basic usage","text":""},{"location":"basic_usage/#basic-usage","title":"Basic Usage","text":""},{"location":"basic_usage/#local-dataset","title":"Local Dataset","text":"<pre><code>import lazybids\ndataset_dir = './templates/'\nds = lazybids.Dataset.from_folder(dataset_dir, load_scans_in_memory=False)\nprint(ds)\n</code></pre>"},{"location":"basic_usage/#remote-dataset-via-lazybids-ui-server","title":"Remote Dataset (via lazybids-ui server)","text":"<pre><code>import lazybids\nconnection = lazybids.Connection(\"http://localhost:8000\")\nds = lazybids.connection.get_dataset('ds005360')\nprint(ds)\n</code></pre>"},{"location":"basic_usage/#working-with-bids-objects","title":"Working with BIDS Objects","text":"<p>LazyBIDS represents BIDS data as a hierarchy of objects:</p> <ol> <li>Dataset</li> <li>Subject</li> <li>Session</li> <li>Scan</li> </ol> <p>Each level can be accessed and iterated over using dictionary-like syntax.</p>"},{"location":"basic_usage/#subjects","title":"Subjects","text":"<pre><code>for subject in ds.subjects.values():\n    print(subject)\n</code></pre>"},{"location":"basic_usage/#sessions","title":"Sessions","text":"<pre><code>for ses in subject.sessions.values():\n    print(ses)\n</code></pre>"},{"location":"basic_usage/#scans","title":"Scans","text":"<pre><code>for scan in ses.scans.values():\n    print(scan)\n</code></pre>"},{"location":"basic_usage/#accessing-scan-data","title":"Accessing Scan Data","text":"<p>LazyBIDS provides multiple ways to access scan data:</p> <pre><code># As a SimpleITK Image\nprint(type(scan.data))\n# As a numpy array\nprint(type(scan.numpy))\nprint(f\"Shape: {scan.numpy.shape}\")\n</code></pre>"},{"location":"basic_usage/#memory-management","title":"Memory Management","text":"<p>LazyBIDS allows fine-grained control over memory usage:</p> <ul> <li>Use <code>load_scans_in_memory=False</code> when creating a Dataset to avoid loading all scan data into memory</li> <li>Use <code>Dataset.load_scans()</code>, <code>Subject.load_scans()</code>, or <code>Session.load_scans()</code> to load scans selectively</li> <li>Use <code>Scan.load()</code> and <code>Scan.unload()</code> to manage individual scan data</li> </ul>"},{"location":"basic_usage/#metadata-access","title":"Metadata Access","text":"<p>All metadata for BIDS objects can be accessed via the <code>all_metadata</code> property, which combines information from filenames, JSON sidecars, and NIFTI/DICOM metadata.</p>"},{"location":"basic_usage/#working-with-remote-datasets","title":"Working with Remote Datasets","text":"<p>LazyBIDS integrates seamlessly with the lazybids-ui server, allowing you to work with large, online datasets as if they were local. This feature downloads only the parts of the dataset you need, making it efficient for working with extensive collections.</p> <p>To use this feature:</p> <ol> <li>Set up a lazybids-ui server</li> <li>Create a Connection object with the server URL</li> <li>Use the connection to retrieve datasets and interact with them as you would with local data</li> </ol> <pre><code>connection = lazybids.Connection(\"http://your-lazybids-ui-server.com\")\nremote_ds = connection.get_dataset('dataset_name')\nWork with remote_ds as if it were a local dataset\nfor subject in remote_ds.subjects.values():\n    print(subject.participant_id)\n</code></pre>"},{"location":"reference/","title":"Reference","text":""},{"location":"reference/#lazybids.datatypes.Dataset","title":"<code>Dataset</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a BIDS dataset.</p> <p>This class handles dataset-level information, including subjects, metadata, and dataset description.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Name of the dataset.</p> <code>folder</code> <code>Path</code> <p>Path to the dataset folder.</p> <code>json_file</code> <code>Union[Path, None]</code> <p>Path to the dataset description JSON file.</p> <code>participants_json</code> <code>Union[Path, None]</code> <p>Path to the participants JSON file.</p> <code>bids_version</code> <code>Union[str, None]</code> <p>BIDS version of the dataset.</p> <code>subjects</code> <code>Dict[str, Subject]</code> <p>Dictionary of subjects in the dataset.</p> <code>subject_variables_metadata</code> <code>Union[List[Dict[Any, Any]], None]</code> <p>Metadata for subject variables.</p> <p>Methods:</p> Name Description <code>from_folder</code> <p>Create a Dataset object from a folder path.</p> <code>from_json</code> <p>Create a Dataset object from a JSON file.</p> <code>load_scans_in_memory</code> <p>Load all scans in the dataset into memory.</p> <code>load_subjects</code> <p>Load all subjects in the dataset.</p> <code>from_api</code> <p>Create a Dataset object from data fetched from a lazybids-ui server.</p> Source code in <code>lazybids/datatypes.py</code> <pre><code>class Dataset(BaseModel):\n    \"\"\"\n    Represents a BIDS dataset.\n\n    This class handles dataset-level information, including subjects, metadata, and dataset description.\n\n    Attributes:\n        name (str): Name of the dataset.\n        folder (Path): Path to the dataset folder.\n        json_file (Union[Path, None]): Path to the dataset description JSON file.\n        participants_json (Union[Path, None]): Path to the participants JSON file.\n        bids_version (Union[str, None]): BIDS version of the dataset.\n        subjects (Dict[str, Subject]): Dictionary of subjects in the dataset.\n        subject_variables_metadata (Union[List[Dict[Any, Any]], None]): Metadata for subject variables.\n\n    Methods:\n        from_folder: Create a Dataset object from a folder path.\n        from_json: Create a Dataset object from a JSON file.\n        load_scans_in_memory: Load all scans in the dataset into memory.\n        load_subjects: Load all subjects in the dataset.\n        from_api: Create a Dataset object from data fetched from a lazybids-ui server.\n    \"\"\"\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    name: str\n    folder: Path\n    json_file: Union[Path, None] = None\n    participants_json: Union[Path, None] = None\n\n    bids_version: Union[str, None] = None\n    HEDVersion: Union[str, None] = None\n    authors: Union[List[str], None] = None\n    fields: dict = Field(default_factory=dict)\n    description: Union[str, None] = None\n    dataset_type: str = \"\"\n    how_to_acknowledge: str = \"\"\n    acknowledgements: str = \"\"\n    funding: Union[List[str], None] = None\n    ethics_approvals: Union[List[str], None] = None\n    references_and_links: Union[List[str], None] = None\n    source_datasets: Union[List[str], List[Dict], None] = None\n    license: str = \"\"\n    dataset_doi: str = \"\"\n\n    subjects: Dict[str, Subject] = Field(default_factory=dict, repr=False)\n    subject_variables_metadata: Union[List[Dict[Any, Any]], None] = None\n\n    connection: Optional[\"Connection\"] = None\n\n    @classmethod\n    def from_folder(cls, folder_path, load_scans_in_memory=False) -&gt; \"Dataset\":\n        dataset_json = os.path.join(folder_path, \"./dataset_description.json\")\n        assert os.path.isfile(\n            dataset_json\n        ), f\"No dataset_description file found at expected location, this is required!: {os.path.join(folder_path, './dataset_description.json')}\"\n        return cls.from_json(dataset_json, load_scans_in_memory)\n\n    @classmethod\n    def from_json(cls, json_path, load_scans_in_memory=False) -&gt; \"Dataset\":\n        ds = json.load(open(json_path, \"r\"))\n        ds = dict_camel_to_snake(ds)\n        ds[\"folder\"] = os.path.split(json_path)[0]\n        ds[\"json_file\"] = json_path\n        dataset = cls(**ds)\n        if os.path.isfile(os.path.join(dataset.folder, \"/participants.json\")):\n            dataset.participants_json = os.path.join(\n                dataset.folder, \"./participants.json\"\n            )\n            dataset._subject_variables_metadata_from_json()\n        dataset.load_subjects()\n        if load_scans_in_memory:\n            dataset.load_scans_in_memory()\n        return dataset\n\n    def load_scans_in_memory(self):\n        for subject in self.subjects.values():\n            subject.load_scans_in_memory()\n\n    @property\n    def all_meta_data(self):\n        all_data = self.model_dump(exclude=[\"subjects\"])\n        if self.fields:\n            del all_data[\"fields\"]\n            all_data.update(self.fields)\n        return all_data\n\n    def _subject_variables_metadata_from_json(self, json_path=None):\n        if not (json_path):\n            assert (\n                self.participants_json\n            ), \"Dataset.participants_json or json_path needs to be set to load metadata\"\n            json_path = os.path.join(self.folder, \"./participants.json\")\n\n        self.participants_json = json_path\n        self.subject_variables_metadata = (\n            pd.DataFrame.from_dict(json.load(open(json_path, \"r\")))\n            .transpose()\n            .to_dict(\"records\")\n        )\n\n    def load_subjects(self):\n        if not (os.path.isfile(os.path.join(self.folder, \"./participants.tsv\"))):\n            logger.info(\n                f\"No participants.tsv found, loading subjects based on subdirectories\"\n            )\n            subject_folders = glob.glob(os.path.join(self.folder, \"./sub-*\"))\n            for pt_dir in tqdm(\n                subject_folders, desc=\"Loading subjects\", unit=\"subject\"\n            ):\n                subject = Subject.from_folder(pt_dir=pt_dir)\n                self.subjects[subject.participant_id] = subject\n        else:\n            logger.info(\n                f'Loading all subjects from {os.path.join(self.folder, \"./participants.tsv\")}'\n            )\n            df = pd.read_csv(os.path.join(self.folder, \"./participants.tsv\"), sep=\"\\t\")\n            participant_id_available = \"participant_id\" in df.columns.tolist()\n            assert (\n                participant_id_available\n            ), f\"participant_id missing in {os.path.join(self.folder, './participants.tsv')}\"\n            for i, pt in tqdm(\n                df.iterrows(), total=len(df), desc=\"Loading subjects\", unit=\"subject\"\n            ):\n                participant_id = pt[\"participant_id\"]\n                if not (\n                    os.path.isdir(os.path.join(self.folder, f\"./{participant_id}\"))\n                ):\n                    logger.warning(\n                        f\"Missing subject folder for {participant_id}, continuing using only subject variables from \\\n                            {os.path.join(self.folder, './participants.tsv')} for this patient\"\n                    )\n                else:\n                    subject = Subject.from_dict(\n                        pt_dict=pt.to_dict(), dataset_folder=self.folder\n                    )\n                    self.subjects[participant_id] = subject\n\n    @classmethod\n    def from_api(cls, connection: \"Connection\", ds_id: int) -&gt; \"Dataset\":\n        dataset_data = connection.get(f\"/api/dataset/{ds_id}\")\n        subjects_data = connection.get(f\"/api/dataset/{ds_id}/subjects\")\n\n        dataset = cls(**dataset_data)\n        dataset.connection = connection\n        dataset.subjects = {\n            subject[\"participant_id\"]: Subject.from_api(\n                connection, ds_id, subject[\"participant_id\"]\n            )\n            for subject in subjects_data.values()\n        }\n\n        return dataset\n</code></pre>"},{"location":"reference/#lazybids.datatypes.Scan","title":"<code>Scan</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a single scan in a BIDS dataset.</p> <p>This class handles individual scan data, including metadata, file paths, and image data.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The name of the scan.</p> <code>files</code> <code>List[Union[Path, AnyHttpUrl]]</code> <p>List of file paths or URLs associated with the scan.</p> <code>metadata_files</code> <code>List[Union[Path, AnyHttpUrl]]</code> <p>List of metadata file paths or URLs.</p> <code>fields</code> <code>Dict[str, Any]</code> <p>Dictionary of additional fields associated with the scan.</p> <code>table</code> <code>Optional[DataFrame]</code> <p>Tabular data associated with the scan, if any.</p> <code>participant_id</code> <code>Optional[str]</code> <p>ID of the participant this scan belongs to.</p> <code>session_id</code> <code>Optional[str]</code> <p>ID of the session this scan belongs to.</p> <code>data</code> <code>Optional[Image]</code> <p>The image data loaded into memory.</p> <code>numpy</code> <code>Optional[ndarray]</code> <p>The image data loaded into memory as a numpy array.</p> <p>Methods:</p> Name Description <code>from_file</code> <p>Load scan data from a file.</p> <code>from_json</code> <p>Load scan metadata from a JSON file.</p> <code>from_tsv</code> <p>Load tabular data from a TSV file.</p> <code>from_api</code> <p>Create a Scan object from data fetched from a lazybids-ui server.</p> <code>write</code> <p>Write scan data to files.</p> <code>load</code> <p>Load the image data into memory.</p> <code>unload</code> <p>Unload the image data from memory.</p> Source code in <code>lazybids/datatypes.py</code> <pre><code>class Scan(BaseModel, extra=Extra.allow):\n    \"\"\"\n    Represents a single scan in a BIDS dataset.\n\n    This class handles individual scan data, including metadata, file paths, and image data.\n\n    Attributes:\n        name (str): The name of the scan.\n        files (List[Union[Path, AnyHttpUrl]]): List of file paths or URLs associated with the scan.\n        metadata_files (List[Union[Path, AnyHttpUrl]]): List of metadata file paths or URLs.\n        fields (Dict[str, Any]): Dictionary of additional fields associated with the scan.\n        table (Optional[pd.DataFrame]): Tabular data associated with the scan, if any.\n        participant_id (Optional[str]): ID of the participant this scan belongs to.\n        session_id (Optional[str]): ID of the session this scan belongs to.\n        data (Optional[sitk.Image]): The image data loaded into memory.\n        numpy (Optional[np.ndarray]): The image data loaded into memory as a numpy array.\n\n    Methods:\n        from_file: Load scan data from a file.\n        from_json: Load scan metadata from a JSON file.\n        from_tsv: Load tabular data from a TSV file.\n        from_api: Create a Scan object from data fetched from a lazybids-ui server.\n        write: Write scan data to files.\n        load: Load the image data into memory.\n        unload: Unload the image data from memory.\n    \"\"\"\n    model_config = ConfigDict(\n        arbitrary_types_allowed=True,\n        json_encoders={pd.DataFrame: lambda df: df.to_csv(sep=\"\\t\", index=False),\n                       pd.core.frame.DataFrame: lambda df: df.to_csv(sep=\"\\t\", index=False)},\n    )\n    name: str = \"\"\n    files: List[Union[Path, AnyHttpUrl]] = Field(default_factory=list)\n    metadata_files: List[Union[Path, AnyHttpUrl]] = Field(default_factory=list)\n    fields: Dict[str, Any] = Field(default_factory=dict)\n\n    table: Optional[Any|None] = Field(\n\n        description=\"A pandas DataFrame\",\n        example={\"column1\": [1, 2, 3], \"column2\": [\"a\", \"b\", \"c\"]},\n        default_factory=pd.DataFrame,\n    )\n    _loaded: bool = False\n    _cached_image: Optional[sitk.Image] = None\n    participant_id: Optional[str] = None\n    session_id: Optional[str] = None\n    connection: Optional[\"Connection\"] = None\n\n    @computed_field(repr=False)\n    @property    \n    def _table_tsv(self) -&gt; Optional[str]:\n        if self.table is not None:\n            if not self.table.empty:\n                return self.table.to_csv(sep=\"\\t\", index=False)\n            else:\n                return None\n        else:\n            return None\n\n    def from_file(self, file: Union[Path, str, AnyHttpUrl]) -&gt; \"Scan\":\n        if isinstance(file, (Path, str)):\n            self.files = [Path(file)]\n        else:\n            self.files = [file]  # This is a URL\n\n        if not self.name:\n            self.name = get_basename_extension(str(file))[0]\n\n        if isinstance(file, (Path, str)):\n            try:\n                new_fields = read_image_meta_data(file)\n                for k, v in new_fields.items():\n                    if k in self.fields:\n                        if self.fields[k] != v:\n                            raise ValueError(f\"Field {k} is not the same in both files\")\n                    else:\n                        self.fields[k] = v\n            except Exception as e:\n                raise Exception(f\"Error reading image metadata: {str(e)}\")\n\n        return self\n\n    def from_json(self, file: Path) -&gt; \"Scan\":\n        if not (self.name):\n            self.name = get_basename_extension(file)[0]\n        for k, v in json.load(open(file, \"r\")).items():\n            if k in self.fields.keys():\n                assert self.fields[k] == v, f\"Field {k} is not the same in both files\"\n            else:\n                self.fields[k] = v\n        self.metadata_files.append(file)\n        return self\n\n    def from_tsv(self, file: Path) -&gt; \"Scan\":\n        if not (self.name):\n            self.name = get_basename_extension(file)[0]\n        self.table = pd.read_csv(file, sep=\"\\t\")\n        self.metadata_files.append(file)\n        return self\n\n    def write(self, folder):\n\n        for file in self.files + self.metadata_files:\n            new_file = os.path.join(folder, os.path.split(file)[1])\n            shutil.copy(file, new_file)\n            logger.info(\"copying {file} to {new_file}\")\n        if self.table is not None:\n            self.table.to_csv(\n                os.path.join(folder, self.name + \".tsv\"), sep=\"\\t\", index=False\n            )\n        if self.fields:\n            with open(os.path.join(folder, self.name + \".json\"), \"w\") as outfile:\n                json.dump(self.fields, outfile)\n\n    @property\n    def data(self) -&gt; sitk.Image:\n        if not self._loaded:\n            self.load()\n        return self._cached_image\n\n    @property\n    def numpy(self) -&gt; np.ndarray:\n        self.load()\n        return sitk.GetArrayFromImage(self.data)\n\n    def load(self) -&gt; None:\n        if not self._loaded:\n            try:\n                if all(isinstance(f, (Path, str)) for f in self.files):\n                    self._cached_image = read_image(self.files)\n                else:\n                    with tempfile.TemporaryDirectory() as temp_dir:\n                        self.download(Path(temp_dir))\n                        self._cached_image = read_image(\n                            [\n                                (\n                                    Path(temp_dir) / Path(f.filename).name\n                                    if not isinstance(f, Path)\n                                    else f\n                                )\n                                for f in self.files\n                            ]\n                        )\n                self._loaded = True\n            except Exception as e:\n                raise Exception(f\"Error loading image: {str(e)}\")\n\n    def unload(self) -&gt; None:\n        self._cached_image = None\n        self._loaded = False\n\n    @computed_field\n    @property\n    def n_files(self) -&gt; int:\n        if not (self.files):\n            return 0\n        else:\n            return len(self.files)\n\n    @property\n    def all_meta_data(self) -&gt; dict:\n        all_data = self.model_dump(exclude=[\"data\", \"numpy\"])\n        if self.fields:\n            del all_data[\"fields\"]\n            all_data.update(self.fields)\n\n        return all_data\n\n    @classmethod\n    def from_api(\n        cls,\n        connection: \"Connection\",\n        ds_id: int,\n        sub_id: str,\n        scan_id: str,\n        ses_id: Optional[str] = None,\n        scan_data: Optional[Dict] = None,\n    ) -&gt; \"Scan\":\n        if ses_id:\n            if scan_data is None:\n                scan_data = connection.get(\n                    f\"/api/dataset/{ds_id}/subjects/{sub_id}/sessions/{ses_id}/scans/{scan_id}\"\n                )\n            base_url = f\"/api/dataset/{ds_id}/subject/{sub_id}/session/{ses_id}/scan/{scan_id}/files/\"\n        else:\n            if scan_data is None:\n                scan_data = connection.get(\n                    f\"/api/dataset/{ds_id}/subjects/{sub_id}/scans/{scan_id}\"\n                )\n            base_url = f\"/api/dataset/{ds_id}/subject/{sub_id}/scan/{scan_id}/files/\"\n        if \"_table_tsv\" in scan_data.keys() and not (scan_data[\"_table_tsv\"] is None):\n            scan_data[\"table\"] = pd.read_csv(StringIO(scan_data[\"_table_tsv\"]), sep=\"\\t\")\n        scan = cls(**scan_data)\n        scan.connection = connection\n        scan.files = [\n            AnyHttpUrl(url=urljoin(connection.base_url, f\"{base_url}{Path(f).name}\"))\n            for f in scan.files\n        ]\n        scan.metadata_files = [\n            AnyHttpUrl(url=urljoin(connection.base_url, f\"{base_url}{Path(f).name}\"))\n            for f in scan.metadata_files\n        ]\n\n        return scan\n\n    def download(self, destination: Path):\n        new_files = []\n        new_metadata_files = []\n        for file_list in [self.files, self.metadata_files]:\n            for file in file_list:\n                if not isinstance(\n                    file, Path\n                ):  # Check if the file is a URL, isinstance(f, AnyHttpUrl) errors..\n                    response = self.connection.session.get(file)\n                    response.raise_for_status()\n                    filename = Path(file.path).name\n                    with open(destination / filename, \"wb\") as f:\n                        f.write(response.content)\n                    if file in self.files:\n                        new_files.append(destination / filename)\n                    if file in self.metadata_files:\n                        new_metadata_files.append(destination / filename)\n                else:\n                    if file in self.files:\n                        new_files.append(file)\n                    if file in self.metadata_files:\n                        new_metadata_files.append(file)\n\n        self.files = new_files\n        self.metadata_files = new_metadata_files\n</code></pre>"},{"location":"reference/#lazybids.datatypes.Session","title":"<code>Session</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a session in a BIDS dataset.</p> <p>This class handles session-level data, including scans and metadata.</p> <p>Attributes:</p> Name Type Description <code>folder</code> <code>Optional[Union[Path, None]]</code> <p>Path to the session folder.</p> <code>scans</code> <code>Optional[Dict[str, Scan]]</code> <p>Dictionary of scans in this session.</p> <code>scan_metadata</code> <code>Optional[Union[Dict[Any, Any], None]]</code> <p>Additional metadata for scans.</p> <code>fields</code> <code>Optional[Union[Dict[Any, Any], None]]</code> <p>Additional fields for the session.</p> <code>session_id</code> <code>Optional[str]</code> <p>ID of the session.</p> <code>participant_id</code> <code>Optional[str]</code> <p>ID of the participant this session belongs to.</p> <p>Methods:</p> Name Description <code>from_dict</code> <p>Create a Session object from a dictionary.</p> <code>from_folder</code> <p>Create a Session object from a folder path.</p> <code>load_scans_in_memory</code> <p>Load all scans in this session into memory.</p> <code>from_api</code> <p>Create a Session object from data fetched from a lazybids-ui server.</p> Source code in <code>lazybids/datatypes.py</code> <pre><code>class Session(BaseModel):\n    \"\"\"\n    Represents a session in a BIDS dataset.\n\n    This class handles session-level data, including scans and metadata.\n\n    Attributes:\n        folder (Optional[Union[Path, None]]): Path to the session folder.\n        scans (Optional[Dict[str, Scan]]): Dictionary of scans in this session.\n        scan_metadata (Optional[Union[Dict[Any, Any], None]]): Additional metadata for scans.\n        fields (Optional[Union[Dict[Any, Any], None]]): Additional fields for the session.\n        session_id (Optional[str]): ID of the session.\n        participant_id (Optional[str]): ID of the participant this session belongs to.\n\n    Methods:\n        from_dict: Create a Session object from a dictionary.\n        from_folder: Create a Session object from a folder path.\n        load_scans_in_memory: Load all scans in this session into memory.\n        from_api: Create a Session object from data fetched from a lazybids-ui server.\n    \"\"\"\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    folder: Optional[Union[Path, None]] = None\n    scans: Optional[Dict[str, Scan]] = Field(default_factory=dict, repr=False)\n    scan_metadata: Optional[Union[Dict[Any, Any], None]] = Field(\n        default_factory=dict, repr=False\n    )\n    fields: Optional[Union[Dict[Any, Any], None]] = None\n    load_scans = load_scans\n    path_vars_keys: Optional[List[str]] = Field(default_factory=list)\n    session_id: Optional[str] = None\n    participant_id: Optional[str] = None\n    connection: Optional[\"Connection\"] = None\n\n    def from_dict(exp_dict=None, dataset_folder=\"\") -&gt; \"Session\":\n        if os.path.isdir(\n            os.path.join(\n                dataset_folder,\n                \"./\",\n                exp_dict[\"participant_id\"],\n                \"./\" + exp_dict[\"session_id\"],\n            )\n        ):\n            exp_dict[\"folder\"] = os.path.join(\n                dataset_folder,\n                \"./\",\n                exp_dict[\"participant_id\"],\n                \"./\" + exp_dict[\"session_id\"],\n            )\n        ses = Session(**exp_dict)\n        if exp_dict[\"folder\"]:\n            ses.load_scans()\n        return ses\n\n    @classmethod\n    def from_folder(cls, exp_dir: str = \"\") -&gt; \"Session\":\n        assert os.path.isdir(exp_dir), \"Folder does not exist\"\n        pt_dict = {\"participant_id\": os.path.split(exp_dir)[1], \"folder\": exp_dir}\n        path_vars_dict = get_vars_from_path(exp_dir)\n\n        for path_key, path_value in path_vars_dict.items():\n            if path_key in pt_dict.keys():\n                if not (path_value == pt_dict[path_key]):\n                    logger.warning(\n                        f\"{path_key} does not correspond between .tsv and folder, folder value: {path_value}, tsv value: {pt_dict[path_key]}\"\n                    )\n                    logger.warning(f\"Saving folders {path_key} as folder_{path_key}\")\n                    pt_dict[\"folder_\" + path_key] = path_value\n            else:\n                pt_dict[path_key] = path_value\n        session = cls(**pt_dict)\n        session.path_vars_keys = list(path_vars_dict.keys())\n        session.load_scans()\n        return session\n\n    def load_scans_in_memory(self):\n        for scan in self.scans.values():\n            scan.load()\n\n    @computed_field\n    @property\n    def n_scans(self) -&gt; int:\n        if not (self.scans):\n            return 0\n        else:\n            return len(self.scans)\n\n    @property\n    def all_meta_data(self):\n        all_data = self.model_dump(exclude=[\"scans\"])\n        if self.fields:\n            del all_data[\"fields\"]\n            all_data.update(self.fields)\n        return all_data\n\n    @classmethod\n    def from_api(\n        cls, connection: \"Connection\", ds_id: int, sub_id: str, ses_id: str\n    ) -&gt; \"Session\":\n        session_data = connection.get(\n            f\"/api/dataset/{ds_id}/subjects/{sub_id}/sessions/{ses_id}\"\n        )\n        scans_data = connection.get(\n            f\"/api/dataset/{ds_id}/subjects/{sub_id}/sessions/{ses_id}/scans\"\n        )\n\n        session = cls(**session_data)\n        session.connection = connection\n        for scan in scans_data.values():\n            session.scans[scan[\"name\"]] = Scan.from_api(\n                connection,\n                ds_id,\n                sub_id,\n                ses_id=ses_id,\n                scan_id=scan[\"name\"],\n                scan_data=scan,\n            )\n        return session\n</code></pre>"},{"location":"reference/#lazybids.datatypes.Subject","title":"<code>Subject</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Represents a subject in a BIDS dataset.</p> <p>This class handles subject-level data, including sessions, scans, and metadata.</p> <p>Attributes:</p> Name Type Description <code>participant_id</code> <code>Optional[Union[str, None]]</code> <p>ID of the subject.</p> <code>folder</code> <code>Optional[Union[Path, None]]</code> <p>Path to the subject folder.</p> <code>sessions</code> <code>Optional[Dict[str, Session]]</code> <p>Dictionary of sessions for this subject.</p> <code>scans</code> <code>Optional[Dict[str, Scan]]</code> <p>Dictionary of scans directly associated with this subject.</p> <code>scan_metadata</code> <code>Optional[Union[Dict[Any, Any], None]]</code> <p>Additional metadata for scans.</p> <code>fields</code> <code>Optional[Union[Dict[Any, Any], None]]</code> <p>Additional fields for the subject.</p> <p>Methods:</p> Name Description <code>from_dict</code> <p>Create a Subject object from a dictionary.</p> <code>from_folder</code> <p>Create a Subject object from a folder path.</p> <code>load_sessions</code> <p>Load all sessions for this subject.</p> <code>load_scans_in_memory</code> <p>Load all scans for this subject into memory.</p> <code>from_api</code> <p>Create a Subject object from data fetched from a lazybids-ui server.</p> Source code in <code>lazybids/datatypes.py</code> <pre><code>class Subject(BaseModel):\n    \"\"\"\n    Represents a subject in a BIDS dataset.\n\n    This class handles subject-level data, including sessions, scans, and metadata.\n\n    Attributes:\n        participant_id (Optional[Union[str, None]]): ID of the subject.\n        folder (Optional[Union[Path, None]]): Path to the subject folder.\n        sessions (Optional[Dict[str, Session]]): Dictionary of sessions for this subject.\n        scans (Optional[Dict[str, Scan]]): Dictionary of scans directly associated with this subject.\n        scan_metadata (Optional[Union[Dict[Any, Any], None]]): Additional metadata for scans.\n        fields (Optional[Union[Dict[Any, Any], None]]): Additional fields for the subject.\n\n    Methods:\n        from_dict: Create a Subject object from a dictionary.\n        from_folder: Create a Subject object from a folder path.\n        load_sessions: Load all sessions for this subject.\n        load_scans_in_memory: Load all scans for this subject into memory.\n        from_api: Create a Subject object from data fetched from a lazybids-ui server.\n    \"\"\"\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    participant_id: Optional[Union[str, None]]\n    folder: Optional[Union[Path, None]] = None\n    sessions: Optional[Dict[str, Session]] = Field(default_factory=dict, repr=False)\n    scans: Optional[Dict[str, Scan]] = Field(default_factory=dict, repr=False)\n    scan_metadata: Optional[Union[Dict[Any, Any], None]] = Field(\n        default_factory=dict, repr=False\n    )\n    fields: Optional[Union[Dict[Any, Any], None]] = None\n    path_vars_keys: Optional[List[str]] = Field(default_factory=list)\n    load_scans = load_scans\n    connection: Optional[\"Connection\"] = None\n\n    def from_dict(pt_dict=None, dataset_folder=\"\") -&gt; \"Subject\":\n        if os.path.isdir(os.path.join(dataset_folder, \"./\", pt_dict[\"participant_id\"])):\n            pt_dict[\"folder\"] = os.path.join(\n                dataset_folder, \"./\", pt_dict[\"participant_id\"]\n            )\n        subject = Subject(**pt_dict)\n        if pt_dict[\"folder\"]:\n            subject.load_sessions()\n        subject.load_scans()\n        return subject\n\n    @classmethod\n    def from_folder(cls, pt_dir: str = \"\") -&gt; \"Subject\":\n        assert os.path.isdir(pt_dir), \"Folder does not exist\"\n        pt_dict = {\"participant_id\": os.path.split(pt_dir)[1], \"folder\": pt_dir}\n        path_vars_dict = get_vars_from_path(pt_dir)\n\n        for path_key, path_value in path_vars_dict.items():\n            if path_key in pt_dict.keys():\n                if not (path_value == pt_dict[path_key]):\n                    logger.warning(\n                        f\"{path_key} does not correspond between .tsv and folder, folder value: {path_value}, tsv value: {pt_dict[path_key]}\"\n                    )\n                    logger.warning(f\"Saving folders {path_key} as folder_{path_key}\")\n                    pt_dict[\"folder_\" + path_key] = path_value\n            else:\n                pt_dict[path_key] = path_value\n        subject = cls(**pt_dict)\n        subject.path_vars_keys = list(path_vars_dict.keys())\n        subject.load_sessions()\n        subject.load_scans()\n        return subject\n\n    def load_sessions(self):\n        assert self.folder, \"Subject folder needs to be set to load sessions\"\n        logger.info(f\"Loading sessions for participant {self.participant_id}\")\n        session_folders = glob.glob(os.path.join(self.folder, \"./ses-*\"))\n        for exp_folder in tqdm(\n            session_folders, desc=\"Loading sessions\", unit=\"session\"\n        ):\n            if os.path.isdir(exp_folder):\n                ses = Session.from_folder(exp_folder)\n                self.sessions[ses.session_id] = ses\n                logger.debug(f\"Loaded session: {ses.session_id}\")\n\n    def load_scans_in_memory(self):\n        for scan in self.scans.values():\n            scan.load()\n        for ses in self.sessions.values():\n            ses.load_scans_in_memory()\n\n    @computed_field\n    @property\n    def n_sessions(self) -&gt; int:\n        return len(self.sessions)\n\n    @computed_field\n    @property\n    def n_scans(self) -&gt; int:\n        if not (self.scans):\n            return 0\n        else:\n            return len(self.scans)\n\n    @property\n    def all_meta_data(self):\n        all_data = self.model_dump(exclude=[\"scans\", \"sessions\"])\n        if self.fields:\n            del all_data[\"fields\"]\n            all_data.update(self.fields)\n        return all_data\n\n    @classmethod\n    def from_api(cls, connection: \"Connection\", ds_id: int, sub_id: str) -&gt; \"Subject\":\n        subject_data = connection.get(f\"/api/dataset/{ds_id}/subjects/{sub_id}\")\n        sessions_data = connection.get(\n            f\"/api/dataset/{ds_id}/subjects/{sub_id}/sessions\"\n        )\n        scans_data = connection.get(f\"/api/dataset/{ds_id}/subjects/{sub_id}/scans\")\n\n        subject = cls(**subject_data)\n        subject.connection = connection\n        subject.sessions = {\n            session[\"session_id\"]: Session.from_api(\n                connection, ds_id, sub_id, session[\"session_id\"]\n            )\n            for session in sessions_data.values()\n        }\n        for scan in scans_data.values():\n            subject.scans[scan[\"name\"]] = Scan.from_api(\n                connection, ds_id, sub_id, scan_id=scan[\"name\"], scan_data=scan\n            )\n        return subject\n</code></pre>"}]}